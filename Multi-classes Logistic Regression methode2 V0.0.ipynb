{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3586650c-11ca-4332-ad39-6f032600c6bd",
   "metadata": {},
   "source": [
    "<h1>Multi-classes Logistic Regression methode2 V0.0.ipynb</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36fb7627-402e-4826-93a2-8a35b81808a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: \n",
      "w = [[-0.83151989  0.97185736  0.95880569]\n",
      " [ 1.55164256 -0.23142491 -0.52249688]\n",
      " [-1.66280534  0.41585082  2.57300726]\n",
      " [-1.39268976 -0.32921788  3.40996032]] \n",
      "b= [-0.099996    2.4522364  -1.08569939]\n",
      "\n",
      "x_test =  [[-5.25060772e-02 -5.92373012e-01  7.62758269e-01  1.58046376e+00]\n",
      " [ 1.89829664e-01 -1.97355361e+00  1.37546573e-01 -2.62386821e-01]\n",
      " [-4.16009689e-01  2.63038172e+00 -1.34022653e+00 -1.31544430e+00]\n",
      " [ 1.76501198e+00 -3.62176246e-01  1.44480739e+00  7.90670654e-01]\n",
      " [-1.02184904e+00  7.88807586e-01 -1.28338910e+00 -1.31544430e+00]\n",
      " [ 5.53333275e-01  5.58610819e-01  1.27429511e+00  1.71209594e+00]\n",
      " [-1.02184904e+00  1.01900435e+00 -1.39706395e+00 -1.18381211e+00]\n",
      " [ 1.03800476e+00  9.82172869e-02  5.35408562e-01  3.95774101e-01]\n",
      " [ 1.15917263e+00 -5.92373012e-01  5.92245988e-01  2.64141916e-01]\n",
      " [ 3.10997534e-01 -5.92373012e-01  1.37546573e-01  1.32509732e-01]\n",
      " [ 3.10997534e-01 -1.05276654e+00  1.04694540e+00  2.64141916e-01]\n",
      " [ 6.74501145e-01  3.28414053e-01  4.21733708e-01  3.95774101e-01]\n",
      " [ 3.10997534e-01 -5.92373012e-01  5.35408562e-01  8.77547895e-04]\n",
      " [ 7.95669016e-01 -5.92373012e-01  4.78571135e-01  3.95774101e-01]\n",
      " [ 3.10997534e-01 -3.62176246e-01  5.35408562e-01  2.64141916e-01]\n",
      " [-1.14301691e+00  1.24920112e+00 -1.34022653e+00 -1.44707648e+00]\n",
      " [ 1.89829664e-01 -3.62176246e-01  4.21733708e-01  3.95774101e-01]\n",
      " [-4.16009689e-01 -1.05276654e+00  3.64896281e-01  8.77547895e-04]\n",
      " [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.18381211e+00]\n",
      " [-5.37177559e-01  1.93979142e+00 -1.39706395e+00 -1.05217993e+00]\n",
      " [-2.94841818e-01 -5.92373012e-01  6.49083415e-01  1.05393502e+00]\n",
      " [-2.94841818e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01]\n",
      " [-1.26418478e+00  7.88807586e-01 -1.05603939e+00 -1.31544430e+00]\n",
      " [-1.74885626e+00 -3.62176246e-01 -1.34022653e+00 -1.31544430e+00]\n",
      " [ 4.32165405e-01 -5.92373012e-01  5.92245988e-01  7.90670654e-01]\n",
      " [-1.50652052e+00  1.24920112e+00 -1.56757623e+00 -1.31544430e+00]\n",
      " [-9.00681170e-01  1.70959465e+00 -1.05603939e+00 -1.05217993e+00]\n",
      " [ 4.32165405e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01]\n",
      " [-1.02184904e+00 -1.74335684e+00 -2.60315415e-01 -2.62386821e-01]\n",
      " [-1.02184904e+00  7.88807586e-01 -1.22655167e+00 -1.05217993e+00]] \n",
      "\n",
      "y_test_encoded =  [[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]] \n",
      "\n",
      "y_test =  [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0] \n",
      "\n",
      "y_pred = [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n",
      "\n",
      "accuracy : 100.0, %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, X:np.array, y:np.array, alpha:float = 0.01, n_iteration:int = 10000, tolerance:float = 0.1):\n",
    "        self.y_pred = np.empty(X.shape[0])\n",
    "        self.w = np.random.rand(X.shape[1], y.shape[1])\n",
    "        self.b = np.random.rand(y.shape[1])\n",
    "        self.alpha = alpha\n",
    "        self.n_iteration = n_iteration\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        \n",
    "    def softmax(self, X):\n",
    "        z = X@self.w + self.b\n",
    "        soft = np.exp(z)/np.sum(np.exp(z), axis = 1)[:,None]\n",
    "        return soft\n",
    "                \n",
    "    def fit(self, X, y):\n",
    "        iteration = 0\n",
    "        precision = np.inf\n",
    "        n = len(y)\n",
    "        while precision > self.tolerance and iteration < self.n_iteration:\n",
    "            z = self.softmax(X)\n",
    "            dw = (1/n)*X.T@(z - y)\n",
    "            db = (1/n)*sum(z - y)\n",
    "            self.w -= self.alpha*dw\n",
    "            self.b -= self.alpha*db\n",
    "            precision = np.max(abs(sum(y*np.log(z))))\n",
    "            iteration += 1\n",
    "        return self.w, self.b, precision, dw, db\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = self.softmax(X)\n",
    "        self.y_pred = np.argmax(z, axis = 1)\n",
    "        return self.y_pred\n",
    "\n",
    "    def accuracy(self, y, y_pred):\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        return 100*(sum(np.array(y == y_pred))/len(y)).round(2)\n",
    "\n",
    "def main():\n",
    "    global X, y, model, dw, db, precision\n",
    "    '''\n",
    "    X = np.random.randint(0,10, size = (100,3))\n",
    "    y = np.array(random.choices(['a', 'b', 'c'], k = X.shape[0]))\n",
    "    '''\n",
    "\n",
    "    from sklearn.datasets import load_iris\n",
    "    data = load_iris()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    enc = OneHotEncoder(sparse_output = False)\n",
    "    y = enc.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    enc = StandardScaler()\n",
    "    X = enc.fit_transform(X)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "    \n",
    "    model = LogisticRegression(x_train, y_train)\n",
    "    \n",
    "    w, b, precision, dw, db = model.fit(x_train, y_train)\n",
    "    print(f'model: \\nw = {w} \\nb= {b}\\n')\n",
    "    print('x_test = ', x_test, '\\n')\n",
    "    print('y_test_encoded = ', y_test, '\\n')\n",
    "    print('y_test = ', np.argmax(y_test, axis = 1), '\\n')\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(f'y_pred = {model.y_pred}\\n')\n",
    "    \n",
    "    print(f'accuracy : {model.accuracy(y_test, model.y_pred)}, %')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac948a37-0a34-43bb-bc68-8be66fe99511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
